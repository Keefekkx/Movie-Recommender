{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1745563747129,
     "user": {
      "displayName": "Keefe Kuan",
      "userId": "03009709165086998908"
     },
     "user_tz": -480
    },
    "id": "cZ01HZKBjfRs"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix, coo_matrix, hstack\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1745563747203,
     "user": {
      "displayName": "Keefe Kuan",
      "userId": "03009709165086998908"
     },
     "user_tz": -480
    },
    "id": "6nBJeCazjlA3"
   },
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Constants\n",
    "K_VALUES = [5, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1745563747457,
     "user": {
      "displayName": "Keefe Kuan",
      "userId": "03009709165086998908"
     },
     "user_tz": -480
    },
    "id": "Gvpy9qYtjtIK"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train.txt\", sep=\"\\t\", names=[\"user_id\", \"movie_id\", \"weight\"])\n",
    "df_test  = pd.read_csv(\"../data/test.txt\",  sep=\"\\t\", names=[\"user_id\", \"movie_id\", \"weight\"])\n",
    "df_meta  = pd.read_csv('../data/movies_metadata.csv')\n",
    "df_users = pd.read_csv('../data/users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_O_zRfZVxnVx"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAzLYdzAxqpH"
   },
   "source": [
    "## Stable Mappings & Interaction Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1745563747670,
     "user": {
      "displayName": "Keefe Kuan",
      "userId": "03009709165086998908"
     },
     "user_tz": -480
    },
    "id": "lbXRJv-HkcqU"
   },
   "outputs": [],
   "source": [
    "def build_mappings(df, user_col='user_id', item_col='movie_id'):\n",
    "    # sort to ensure deterministic ordering\n",
    "    users = sorted(df[user_col].unique())\n",
    "    items = sorted(df[item_col].unique())\n",
    "    user2idx = {u: i for i, u in enumerate(users)}\n",
    "    item2idx = {i: j for j, i in enumerate(items)}\n",
    "    return user2idx, item2idx\n",
    "\n",
    "user2idx, item2idx = build_mappings(df_train)\n",
    "idx2user = {v: k for k, v in user2idx.items()}\n",
    "idx2item = {v: k for k, v in item2idx.items()}\n",
    "n_users, n_items = len(user2idx), len(item2idx)\n",
    "\n",
    "def encode_interactions(df):\n",
    "    df = df.copy()\n",
    "    df['user_idx'] = df['user_id'].map(user2idx)\n",
    "    df['item_idx'] = df['movie_id'].map(item2idx)\n",
    "    return df.dropna(subset=['user_idx','item_idx'])\\\n",
    "             .astype({'user_idx':int, 'item_idx':int, 'weight':float})\n",
    "\n",
    "df_train_enc = encode_interactions(df_train)\n",
    "df_test_enc  = encode_interactions(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcCDfmLYxuqn"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1745563747836,
     "user": {
      "displayName": "Keefe Kuan",
      "userId": "03009709165086998908"
     },
     "user_tz": -480
    },
    "id": "81Strxhis-sP"
   },
   "outputs": [],
   "source": [
    "def build_item_features(df_meta, item2idx, n_items):\n",
    "    df = df_meta[df_meta.movie_id.isin(item2idx)].copy()\n",
    "    df['item_idx'] = df['movie_id'].map(item2idx)\n",
    "    df = df.set_index('item_idx').reindex(range(n_items))\n",
    "\n",
    "    mats = []\n",
    "    for col in ['genres','actor','language','country']:\n",
    "        if col in df:\n",
    "            mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "            # ensure each entry is a list (replace NaN or others with empty list)\n",
    "            lists = df[col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "            mats.append(mlb.fit_transform(lists))\n",
    "\n",
    "    tfidf = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "    mats.append(tfidf.fit_transform(df['title'].fillna('')))\n",
    "\n",
    "    bins = np.arange(1900, 2025, 10)\n",
    "    df['year_bin'] = pd.cut(df['year'], bins=bins, labels=bins[:-1])\n",
    "    ohe = OneHotEncoder(sparse_output=True, handle_unknown='ignore')\n",
    "    mats.append(ohe.fit_transform(df[['year_bin']]))\n",
    "\n",
    "    return hstack(mats)\n",
    "\n",
    "item_features = build_item_features(df_meta, item2idx, n_items)\n",
    "\n",
    "# Build user features from df_users\n",
    "def build_user_features(df_users, user2idx, n_users):\n",
    "    df = df_users[df_users.user_id.isin(user2idx)].copy()\n",
    "    df['user_idx'] = df['user_id'].map(user2idx)\n",
    "    df = df.set_index('user_idx').reindex(range(n_users))\n",
    "\n",
    "    mats = []\n",
    "    for col in ['gender','occupation']:\n",
    "        ohe = OneHotEncoder(sparse_output=True, handle_unknown='ignore')\n",
    "        mats.append(ohe.fit_transform(df[[col]]))\n",
    "\n",
    "    bins = [0,18,25,35,45,50,56,101]\n",
    "    df['age_bin'] = pd.cut(df['age'], bins=bins)\n",
    "    ohe_age = OneHotEncoder(sparse_output=True, handle_unknown='ignore')\n",
    "    mats.append(ohe_age.fit_transform(df[['age_bin']]))\n",
    "\n",
    "    return hstack(mats)\n",
    "\n",
    "user_features = build_user_features(df_users, user2idx, n_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-LLGXruxyxA"
   },
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1745563747862,
     "user": {
      "displayName": "Keefe Kuan",
      "userId": "03009709165086998908"
     },
     "user_tz": -480
    },
    "id": "9gOvFgdatE14"
   },
   "outputs": [],
   "source": [
    "def evaluate_metrics_by_user(recommend_fn, df_test, K_values=K_VALUES):\n",
    "    user_truth = df_test.groupby('user_idx')['item_idx'].apply(list).to_dict()\n",
    "    stats = {K:{'prec':[],'rec':[],'hr':[],'ndcg':[],'ap':[]} for K in K_VALUES}\n",
    "\n",
    "    for u, true_items in tqdm(user_truth.items(), total=len(user_truth)):\n",
    "        true_items = [int(x) for x in true_items]\n",
    "        recs = recommend_fn(u, max(K_VALUES))\n",
    "        recs = [int(x) for x in np.asarray(recs).ravel()]\n",
    "\n",
    "        for K in K_VALUES:\n",
    "            topk = recs[:K]\n",
    "            hits = [i for i in topk if i in true_items]\n",
    "            n, R = len(hits), len(true_items)\n",
    "            stats[K]['prec'].append(n/K)\n",
    "            stats[K]['rec'].append(n/R if R else 0)\n",
    "            stats[K]['hr'].append(int(n>0))\n",
    "            if n>0:\n",
    "                dcg = sum(1/math.log2(topk.index(i)+2) for i in hits)\n",
    "                ideal = sum(1/math.log2(r+2) for r in range(min(R,K)))\n",
    "                stats[K]['ndcg'].append(dcg/ideal if ideal else 0)\n",
    "                num_rel=0; s=0\n",
    "                for idx,item in enumerate(topk,1):\n",
    "                    if item in true_items:\n",
    "                        num_rel+=1; s+=num_rel/idx\n",
    "                stats[K]['ap'].append(s/min(R,K))\n",
    "            else:\n",
    "                stats[K]['ndcg'].append(0); stats[K]['ap'].append(0)\n",
    "\n",
    "    return {f\"{m}@{K}\": np.mean(v) for K,metrics in stats.items() for m,v in metrics.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcYoSenTxViD"
   },
   "source": [
    "# Recommender Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1745563747903,
     "user": {
      "displayName": "Keefe Kuan",
      "userId": "03009709165086998908"
     },
     "user_tz": -480
    },
    "id": "m_LCqXj4tGqx"
   },
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    def fit(self, df, item_features=None, user_features=None):\n",
    "        self.pop = df.movie_id.value_counts().index.map(item2idx).tolist()\n",
    "    def recommend(self, u, N):\n",
    "        return self.pop[:N]\n",
    "\n",
    "class MemoryCF:\n",
    "    def __init__(self, mode='user', K=10):\n",
    "        self.mode = mode\n",
    "        self.K = K\n",
    "\n",
    "    def fit(self, df, item_features=None, user_features=None):\n",
    "        rows = df.user_idx\n",
    "        cols = df.item_idx\n",
    "        w    = df.weight\n",
    "        self.mat = csr_matrix((w.values, (rows, cols)), shape=(n_users, n_items))\n",
    "        matrix = self.mat if self.mode == 'user' else self.mat.T\n",
    "        self.sim = cosine_similarity(matrix)\n",
    "\n",
    "    def recommend(self, u, N):\n",
    "        seen = set(self.mat[u].indices)\n",
    "        if self.mode == 'user':\n",
    "            sims = self.sim[u]\n",
    "            neighbors = np.argsort(sims)[::-1][1:self.K+1]\n",
    "            scores = self.mat[neighbors].sum(axis=0).A1\n",
    "        else:\n",
    "            liked = self.mat[u].indices\n",
    "            scores = self.sim[liked].sum(axis=0)\n",
    "            scores[liked] = 0\n",
    "        ranking = np.argsort(scores)[::-1]\n",
    "        return [i for i in ranking if i not in seen][:N]\n",
    "\n",
    "class ALSRecommender:\n",
    "    def __init__(self, factors=64, regularization=0.01,\n",
    "                 iterations=30, alpha=40):\n",
    "        self.params = dict(factors=factors,\n",
    "                           regularization=regularization,\n",
    "                           iterations=iterations,\n",
    "                           alpha=alpha,\n",
    "                           random_state=SEED,\n",
    "                           num_threads=1)   # force single-thread in ALS\n",
    "    def fit(self, df, item_features=None, user_features=None):\n",
    "        # **DO NOT pre-scale** data here; let ALS handle alpha internally\n",
    "        rows = df.user_idx\n",
    "        cols = df.item_idx\n",
    "        w    = df.weight\n",
    "        ui = coo_matrix((w.values, (rows, cols)),\n",
    "                        shape=(n_users, n_items)).tocsr()\n",
    "        self.model = AlternatingLeastSquares(**self.params)\n",
    "        self.model.fit(ui)\n",
    "        self.ui = ui\n",
    "\n",
    "    def recommend(self, u, N):\n",
    "        item_ids, scores = self.model.recommend(\n",
    "            userid=u,\n",
    "            user_items=self.ui[u],\n",
    "            N=N,\n",
    "            filter_already_liked_items=True\n",
    "        )\n",
    "        return [int(i) for i in item_ids]\n",
    "\n",
    "class LightFMHybrid:\n",
    "    def __init__(self, **kw):\n",
    "        self.kw = kw\n",
    "\n",
    "    def fit(self, df, item_features=None, user_features=None):\n",
    "        rows = df.user_idx\n",
    "        cols = df.item_idx\n",
    "        inter = coo_matrix((np.ones(len(df)), (rows, cols)), shape=(n_users, n_items))\n",
    "        self.model = LightFM(**self.kw)\n",
    "        self.model.fit(\n",
    "            inter,\n",
    "            item_features=item_features,\n",
    "            user_features=user_features,\n",
    "            epochs=10,\n",
    "            num_threads=4,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    def recommend(self, u, N):\n",
    "        scores = self.model.predict(\n",
    "            np.repeat(u, n_items),\n",
    "            np.arange(n_items),\n",
    "            item_features=item_features,\n",
    "            user_features=user_features\n",
    "        )\n",
    "        return [int(i) for i in np.argsort(-scores)[:N]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMxaxncexZsS"
   },
   "source": [
    "# Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8c0030139e7b4a04bd744938463923f7",
      "05acbe0d036c461999e04ba81a7f4075",
      "1529e6d821674808bb709ec986dfc47f",
      "6541c7c58b2245dd9b98a738d7136550",
      "8b6dacaac2de4a8c9779ff7cfa757ae0",
      "00243beada524031820189bf6305c885",
      "9d427680c75248fda87bfe2c37ff5918",
      "6178497ec4a04649ac217a0df3d158ac",
      "e27e2c250d2d4fe0a9ccdd2683a7a37f",
      "99509a5234134806b59aa2aba421a7df",
      "af291a52c51d461f92fb03db882b8516"
     ]
    },
    "executionInfo": {
     "elapsed": 111352,
     "status": "ok",
     "timestamp": 1745563859270,
     "user": {
      "displayName": "Keefe Kuan",
      "userId": "03009709165086998908"
     },
     "user_tz": -480
    },
    "id": "_c0SsHtctK7Z",
    "outputId": "bbb8aad0-9049-4a23-8e6a-9a64679f57ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ Popularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5390/5390 [00:00<00:00, 13713.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prec@5: 0.0383\n",
      "rec@5: 0.0137\n",
      "hr@5: 0.1538\n",
      "ndcg@5: 0.0385\n",
      "ap@5: 0.0201\n",
      "prec@10: 0.0380\n",
      "rec@10: 0.0267\n",
      "hr@10: 0.2672\n",
      "ndcg@10: 0.0410\n",
      "ap@10: 0.0157\n",
      "prec@20: 0.0397\n",
      "rec@20: 0.0562\n",
      "hr@20: 0.4445\n",
      "ndcg@20: 0.0517\n",
      "ap@20: 0.0154\n",
      "\n",
      "▶️ UserCF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5390/5390 [00:16<00:00, 324.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prec@5: 0.1030\n",
      "rec@5: 0.0350\n",
      "hr@5: 0.3499\n",
      "ndcg@5: 0.1054\n",
      "ap@5: 0.0612\n",
      "prec@10: 0.0940\n",
      "rec@10: 0.0629\n",
      "hr@10: 0.5074\n",
      "ndcg@10: 0.1058\n",
      "ap@10: 0.0479\n",
      "prec@20: 0.0842\n",
      "rec@20: 0.1101\n",
      "hr@20: 0.6716\n",
      "ndcg@20: 0.1161\n",
      "ap@20: 0.0433\n",
      "\n",
      "▶️ ItemCF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5390/5390 [00:10<00:00, 497.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prec@5: 0.1072\n",
      "rec@5: 0.0355\n",
      "hr@5: 0.3521\n",
      "ndcg@5: 0.1114\n",
      "ap@5: 0.0667\n",
      "prec@10: 0.0981\n",
      "rec@10: 0.0640\n",
      "hr@10: 0.5024\n",
      "ndcg@10: 0.1108\n",
      "ap@10: 0.0521\n",
      "prec@20: 0.0864\n",
      "rec@20: 0.1083\n",
      "hr@20: 0.6568\n",
      "ndcg@20: 0.1188\n",
      "ap@20: 0.0459\n",
      "\n",
      "▶️ ALS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.11/dist-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 2 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0030139e7b4a04bd744938463923f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5390/5390 [00:01<00:00, 3109.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prec@5: 0.0815\n",
      "rec@5: 0.0328\n",
      "hr@5: 0.3221\n",
      "ndcg@5: 0.0829\n",
      "ap@5: 0.0439\n",
      "prec@10: 0.0764\n",
      "rec@10: 0.0592\n",
      "hr@10: 0.4878\n",
      "ndcg@10: 0.0867\n",
      "ap@10: 0.0357\n",
      "prec@20: 0.0734\n",
      "rec@20: 0.1117\n",
      "hr@20: 0.6931\n",
      "ndcg@20: 0.1042\n",
      "ap@20: 0.0355\n",
      "\n",
      "▶️ LightFM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [00:41<00:00,  4.12s/it]\n",
      "100%|██████████| 5390/5390 [00:21<00:00, 249.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prec@5: 0.0317\n",
      "rec@5: 0.0100\n",
      "hr@5: 0.1371\n",
      "ndcg@5: 0.0329\n",
      "ap@5: 0.0170\n",
      "prec@10: 0.0295\n",
      "rec@10: 0.0174\n",
      "hr@10: 0.2288\n",
      "ndcg@10: 0.0325\n",
      "ap@10: 0.0120\n",
      "prec@20: 0.0281\n",
      "rec@20: 0.0332\n",
      "hr@20: 0.3675\n",
      "ndcg@20: 0.0363\n",
      "ap@20: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Popularity': PopularityRecommender(),\n",
    "    'UserCF':    MemoryCF('user', 10),\n",
    "    'ItemCF':    MemoryCF('item', 10),\n",
    "    'ALS':       ALSRecommender(factors=64, regularization=0.01, iterations=30, alpha=40),\n",
    "    'LightFM':   LightFMHybrid(loss='warp', no_components=128, learning_rate=0.05, random_state=SEED)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n▶️ {name}\")\n",
    "    model.fit(df_train_enc, item_features=item_features, user_features=user_features)\n",
    "    metrics = evaluate_metrics_by_user(model.recommend, df_test_enc)\n",
    "    print()\n",
    "    for metric, score in metrics.items():\n",
    "        print(f\"{metric}: {score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM9CFIEx/2sUpTxjTbx6sGt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
